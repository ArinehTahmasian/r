---
title: Reproducibility 
teaching: 10
exercises: 45
questions: 
  - How can I ensure my code is reproducible?
objectives:
  - Understand the value of reproducibility
  - Identify the key considerations to enable reproducibility
keypoints:
  - A script is a discrete unit of analysis
  - A script will be run in the context of an environment
  - Software (and compute) dependencies need to be considered
source: Rmd
---

```{r, include=FALSE}
source("../bin/chunk-options.R")
knitr_fig_path("18-")
```

A core concept of reproducible research is that all steps from raw data to results are available
and well documented so that others can make use of them. The explanation of research methods in 
published papers is rarely detailed enough to recreate the results, and so there is no easy way to
confirm the published results, or apply the methods in a new context. 

Taking the first step towards making your research more reproducible is easy when your analysis is 
recorded in code. Just collect your analysis code into a script and make it available with
your raw data and results. Some people have an aversion to letting other people look at their code,
but give it a try as there are a lot of potential benefits.

## Benefits of reproducibility

* It makes it easy for your methods to be reused in the future. This may be a colleague trying to 
apply your approach in their own project or yourself in a year or two trying to compare newly
collected data with your previous work.

* You are more likely to catch mistakes in your analysis in the process of documenting it for others.
Since each step in the process is recorded, it also makes it easy to trace back to find when the 
mistake was introduced and correct it.

* Other people will be able to spot mistakes in your code. More people looking at your code means 
more opportunity to carch and correct errors, ensuring that your results are accurate.

## Reproducibility with R

Besides recording your analysis in a script, there are a few other considerations to increase the
reproducibility of your research.

Firstly, your script will run with the R environment that launched it. Use the RStudio Environment 
pane to explore your current environment after completing these lessons. Or use `ls()` to view the 
data in your environment, and `loadedNamespaces()` to view the packages that are loaded in the 
environment. 

> ## Challenge 1
> Create a fresh R session (in RStudio select "Session" > "New Session") and compare the environments.
> What effect might this have on a script?
{: .challenge}

To make sure that your script is self-contained, always test that it performs as expected in a 
fresh session.

Secondly, make sure that your analysis is documented clearly. This might mean adding short comments 
to your code as you write it, or for longer form documentation you can create a plain text README 
file in your project's directory (eg. to explain the experimental design). An alternative approach
is to use an [R markdown](https://rmarkdown.rstudio.com) document, which lets you mix together text 
and code more easily. 

When documenting your process, it is often more important to record the *decisions* that you make
rather than just describing what your code is doing. Explaining *why* your analysis is taking a 
particular approach is far more valuable for other people to understand it.

Finally, record precisely which software versions were used to produce your results. Software can
be updated and may not always produce the same results as older versions. Record the version of R
you are using, as well as the versions of any packages you use. This information can be found with
`sessionInfo()`

> ## Putting it all together
> 
> As a final challenge, you will complete an end to end data analysis task in a reproducible fashion.
>
> Create a new project and download two data files from the Bureau of Meterology, one
> containing [meterological information]({{ page.root }}{% link data/BOM_data.csv %}),
> and one containing [metadata about weather stations](({{ page.root }}{% link data/BOM_stations.csv %}))
> 
> Take some time to explore the data files and understand what they contain, then write a script 
> that answers the following questions:
> * **1**: For each station, how many days have a minimum temperature, a maximum temperature and 
> a rainfall measurement recorded?
> * **2**: Which month saw the lowest difference between minimum and maximum temperatures in a day?
> And which state saw the highest?
> * **3**: Which state had the lowest average monthly minimum temperature after excluding sites
> more than 500m above sea level.
> * **4**: Design your own question. What is something you wanted to find out after exploring what
> the data set contained. Or was there something that surprised you when working with the data.
> Write the answer to question 4 out to a file.
>
> Once you are finished, swap scripts with another person, along with any instructions they will need
> to make sure it works. Can you get their script to run? 
> 
> Compare your code for the first three questions. Were there any instances where you took different
> approaches to solve the same problem? 
{: .challenge}


